{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "csv_files = glob.glob('hashtags/*.{}'.format('csv'))\n",
    "\n",
    "df_concat = pd.concat([pd.read_csv(f,usecols=(1,2),converters={2:ast.literal_eval}) for f in csv_files], ignore_index=True)\n",
    "\n",
    "df_concat.to_csv('hashtags_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3330 entries, 0 to 3995\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   avatar    3330 non-null   object\n",
      " 1   hashtags  3330 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 78.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df_concat\n",
    "\n",
    "# indexEmpty = df[ (df['hashtags'])].index\n",
    "\n",
    "# df.drop(indexEmpty, inplace=True)\n",
    "df = df[df.astype(str)['hashtags'] != '[]']\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nx/cjw5t0552msc_r1yfk4m77tr0000gn/T/ipykernel_71392/186257905.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_decomposed['words'] = df_decomposed.apply(lambda row: decomposed_hashtags(row['hashtags']),axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                avatar                                           hashtags  \\\n0           sinemunsal                [#tbt, #pink, #Aydınlıkevler,, #tb]   \n1            ellekorea  [#ELLECoverstar, #제작비지원, #공유, #GONGYOO, #엘르5월호...   \n2             ashanegi  [#mentalbehene, #instareels, #reelitfeelit, #w...   \n3       portadosfundos  [#BBB21., #cozinhacompimenta, #bbb, #bbb21, #b...   \n4            tobibakre  [#WellnessWithJumia, #Camon16, #CBeyond, #Tobi...   \n..                 ...                                                ...   \n121        baranikster  [#שירליוםראשון, #טונה, #🐟, #לפיההנחיות, #חייאת...   \n122       movierapture  [#Galaxyofentertainment, #cinephile, #movierec...   \n123  photo._.grammetry  [#noodles, #reelsinstagram, #ketofy, #reelitfe...   \n124     hiddengemindia  [#foodreels, #cakeofinstagram, #rasmalaicake, ...   \n125   thegianninatwins  [#arbonne, #bonbabe, #coffeelover, #plantbased...   \n\n                                                 words  \n0                         [tbt, aydnlkevler, tb, pink]  \n1    [elle, gong, yoo, up, xs, close, 5, j12, 3, st...  \n2    [you, collaboration, bollywood, dancing, menta...  \n3    [nelly, os, coach, porta, jogo, do, are, comed...  \n4    [your, nigeria, is, 4mazfo, to, keep, trans, w...  \n..                                                 ...  \n121                                                 []  \n122  [cinema, gram, reviews, ram, is, entertainment...  \n123  [gram, super, is, veggie, new, go, savour, sha...  \n124  [gram, cheese, try, ram, decorating, birthday,...  \n125  [protein, plant, based, bon, lover, coffee, ba...  \n\n[100 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>avatar</th>\n      <th>hashtags</th>\n      <th>words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sinemunsal</td>\n      <td>[#tbt, #pink, #Aydınlıkevler,, #tb]</td>\n      <td>[tbt, aydnlkevler, tb, pink]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ellekorea</td>\n      <td>[#ELLECoverstar, #제작비지원, #공유, #GONGYOO, #엘르5월호...</td>\n      <td>[elle, gong, yoo, up, xs, close, 5, j12, 3, st...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ashanegi</td>\n      <td>[#mentalbehene, #instareels, #reelitfeelit, #w...</td>\n      <td>[you, collaboration, bollywood, dancing, menta...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>portadosfundos</td>\n      <td>[#BBB21., #cozinhacompimenta, #bbb, #bbb21, #b...</td>\n      <td>[nelly, os, coach, porta, jogo, do, are, comed...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tobibakre</td>\n      <td>[#WellnessWithJumia, #Camon16, #CBeyond, #Tobi...</td>\n      <td>[your, nigeria, is, 4mazfo, to, keep, trans, w...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>baranikster</td>\n      <td>[#שירליוםראשון, #טונה, #🐟, #לפיההנחיות, #חייאת...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>movierapture</td>\n      <td>[#Galaxyofentertainment, #cinephile, #movierec...</td>\n      <td>[cinema, gram, reviews, ram, is, entertainment...</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>photo._.grammetry</td>\n      <td>[#noodles, #reelsinstagram, #ketofy, #reelitfe...</td>\n      <td>[gram, super, is, veggie, new, go, savour, sha...</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>hiddengemindia</td>\n      <td>[#foodreels, #cakeofinstagram, #rasmalaicake, ...</td>\n      <td>[gram, cheese, try, ram, decorating, birthday,...</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>thegianninatwins</td>\n      <td>[#arbonne, #bonbabe, #coffeelover, #plantbased...</td>\n      <td>[protein, plant, based, bon, lover, coffee, ba...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wordsegment import load, segment\n",
    "load()\n",
    "\n",
    "def decomposed_hashtags(hashtags):\n",
    "    flat_list = []\n",
    "    for hashtag in hashtags:\n",
    "        for segm in segment(hashtag):\n",
    "            flat_list.append(segm)\n",
    "    return list(set(flat_list))\n",
    "    # return set()\n",
    "\n",
    "df_decomposed = df.head(100)\n",
    "\n",
    "df_decomposed['words'] = df_decomposed.apply(lambda row: decomposed_hashtags(row['hashtags']),axis=1)\n",
    "\n",
    "df_decomposed\n",
    "# df_100.to_csv('decomposed_hashtags_1000.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pyspark                                 # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "import urllib\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark_df = spark.createDataFrame(df_decomposed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "               avatar                                           hashtags  \\\n0          sinemunsal                [#tbt, #pink, #Aydınlıkevler,, #tb]   \n1           ellekorea  [#ELLECoverstar, #제작비지원, #공유, #GONGYOO, #엘르5월호...   \n2            ashanegi  [#mentalbehene, #instareels, #reelitfeelit, #w...   \n3      portadosfundos  [#BBB21., #cozinhacompimenta, #bbb, #bbb21, #b...   \n4           tobibakre  [#WellnessWithJumia, #Camon16, #CBeyond, #Tobi...   \n..                ...                                                ...   \n95        baranikster  [#שירליוםראשון, #טונה, #🐟, #לפיההנחיות, #חייאת...   \n96       movierapture  [#Galaxyofentertainment, #cinephile, #movierec...   \n97  photo._.grammetry  [#noodles, #reelsinstagram, #ketofy, #reelitfe...   \n98     hiddengemindia  [#foodreels, #cakeofinstagram, #rasmalaicake, ...   \n99   thegianninatwins  [#arbonne, #bonbabe, #coffeelover, #plantbased...   \n\n                                                words  \n0                        [tbt, aydnlkevler, tb, pink]  \n1   [elle, gong, yoo, up, xs, close, 5, j12, 3, st...  \n2   [you, collaboration, bollywood, dancing, menta...  \n3   [nelly, os, coach, porta, jogo, do, are, comed...  \n4   [your, nigeria, is, 4mazfo, to, keep, trans, w...  \n..                                                ...  \n95                                                 []  \n96  [cinema, gram, reviews, ram, is, entertainment...  \n97  [gram, super, is, veggie, new, go, savour, sha...  \n98  [gram, cheese, try, ram, decorating, birthday,...  \n99  [protein, plant, based, bon, lover, coffee, ba...  \n\n[100 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>avatar</th>\n      <th>hashtags</th>\n      <th>words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sinemunsal</td>\n      <td>[#tbt, #pink, #Aydınlıkevler,, #tb]</td>\n      <td>[tbt, aydnlkevler, tb, pink]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ellekorea</td>\n      <td>[#ELLECoverstar, #제작비지원, #공유, #GONGYOO, #엘르5월호...</td>\n      <td>[elle, gong, yoo, up, xs, close, 5, j12, 3, st...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ashanegi</td>\n      <td>[#mentalbehene, #instareels, #reelitfeelit, #w...</td>\n      <td>[you, collaboration, bollywood, dancing, menta...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>portadosfundos</td>\n      <td>[#BBB21., #cozinhacompimenta, #bbb, #bbb21, #b...</td>\n      <td>[nelly, os, coach, porta, jogo, do, are, comed...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tobibakre</td>\n      <td>[#WellnessWithJumia, #Camon16, #CBeyond, #Tobi...</td>\n      <td>[your, nigeria, is, 4mazfo, to, keep, trans, w...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>baranikster</td>\n      <td>[#שירליוםראשון, #טונה, #🐟, #לפיההנחיות, #חייאת...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>movierapture</td>\n      <td>[#Galaxyofentertainment, #cinephile, #movierec...</td>\n      <td>[cinema, gram, reviews, ram, is, entertainment...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>photo._.grammetry</td>\n      <td>[#noodles, #reelsinstagram, #ketofy, #reelitfe...</td>\n      <td>[gram, super, is, veggie, new, go, savour, sha...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>hiddengemindia</td>\n      <td>[#foodreels, #cakeofinstagram, #rasmalaicake, ...</td>\n      <td>[gram, cheese, try, ram, decorating, birthday,...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>thegianninatwins</td>\n      <td>[#arbonne, #bonbabe, #coffeelover, #plantbased...</td>\n      <td>[protein, plant, based, bon, lover, coffee, ba...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.toPandas()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/14 18:08:41 WARN StopWordsRemover: Default locale set was [en_RO]; however, it was not found in available locales in JVM, falling back to en_US locale. Set param `locale` in order to respect another locale.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.                 (0 + 0) / 8]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/opt/apache-spark/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/opt/apache-spark/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/Users/crangaantonio/opt/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml.feature import IDF, Tokenizer, StopWordsRemover, CountVectorizer, StringIndexer\n",
    "\n",
    "spark_df = spark.createDataFrame(df.head(100))\n",
    "\n",
    "wordsData = spark_df\n",
    "\n",
    "decompose_hashtags_udf = udf(lambda row: decomposed_hashtags(row), ArrayType(StringType()))\n",
    "\n",
    "filter_length_udf = udf(lambda row: [x for x in row if len(x) >= 3], ArrayType(StringType()))\n",
    "\n",
    "wordsData = wordsData.withColumn('words',decompose_hashtags_udf(col('hashtags')))\n",
    "wordsData =wordsData.withColumn('words_filtered',filter_length_udf(col('words')))\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words_filtered\", outputCol = \"filtered\", locale=\"en_US\")\n",
    "wordsData = remover.transform(wordsData)\n",
    "wordsData.toPandas()\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"TF\", vocabSize=1000) # keep the most 1000 common words\n",
    "cvModel = cv.fit(wordsData)\n",
    "wordsData = cvModel.transform(wordsData)\n",
    "\n",
    "idf = IDF(inputCol=\"TF\", outputCol=\"features\")\n",
    "idfModel = idf.fit(wordsData)\n",
    "wordsData = idfModel.transform(wordsData)\n",
    "\n",
    "wordsData.toPandas()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
